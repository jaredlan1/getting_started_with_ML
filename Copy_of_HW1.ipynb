{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1zcfhNRrlAaNkP19PeCWz9xvzFRbtBL6p",
      "authorship_tag": "ABX9TyNdxIwaD47KXFtkc8L6BAHo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredlan1/getting_started_with_ML/blob/main/Copy_of_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmqNl56IPsPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class VanillaNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.network = nn.Sequential(\n",
        "        nn.Linear(13.24),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(24,36),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(36,1)\n",
        "    )\n",
        "    def forward(self, x):\n",
        "       self.network(x)"
      ],
      "metadata": {
        "id": "t08hhv3-Pvj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for X, y in dataloader:\n",
        "\n",
        "      # Compute prediction error\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      train_loss += loss.item()\n",
        "    train_loss /= len(dataloader)\n",
        "    print(f\"Train Error: \\n Avg loss: {train_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "15N5rTCdTnWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model, loss_fn):\n",
        "\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "\n",
        "    print(f\"Test loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "aEu8HJQ0UZjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loaddata():\n"
      ],
      "metadata": {
        "id": "fHXRSkYWb4ay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = VanillaNetwork()\n",
        "loss_fn = nn.MSELoss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 372
        },
        "id": "hNbP_sVjRS1S",
        "outputId": "dafcbf5b-7f06-4366-dcc6-0c3a6c246eca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "Linear.__init__() missing 1 required positional argument: 'out_features'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1416862289.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVanillaNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-265850686.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     self.network = nn.Sequential(\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13.24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m36\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Linear.__init__() missing 1 required positional argument: 'out_features'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1000\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loss = train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loss = test(test_dataloader, model, loss_fn)\n",
        "    train_losses.append(train_loss)\n",
        "    test_losses.append(test_loss)\n",
        "plt.figure()\n",
        "plt.plot(range(epochs), train_losses, label='train')\n",
        "plt.plot(range(epochs), test_losses, label='test')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "PnOqBkXPTQLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08fabfc7"
      },
      "source": [
        "# Task\n",
        "Prepare the 'auto-mpg.data' dataset for machine learning by using 'auto-mpg.names' to infer column information, loading the data, handling missing values, encoding categorical features, and splitting the data into training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed31d402"
      },
      "source": [
        "## Load and Parse auto-mpg.names\n",
        "\n",
        "### Subtask:\n",
        "Read the `auto-mpg.names` file to understand the column structure, identify feature names, and determine the target variable ('mpg').\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1333c754"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to download the `auto-mpg.data` and `auto-mpg.names` files. I will use `!wget` command to download these files from the UCI Machine Learning Repository.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8a443ae4"
      },
      "source": [
        "# Task\n",
        "Prepare the 'auto-mpg.data' dataset for machine learning by loading it from `drive/MyDrive/auto-mpg.data`, using `drive/MyDrive/auto-mpg.names` for column information, handling missing values, encoding categorical features, and splitting the data into training and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "015c3ca2"
      },
      "source": [
        "## Load and Parse auto-mpg.names from Drive\n",
        "\n",
        "### Subtask:\n",
        "Read the `auto-mpg.names` file from your `drive/MyDrive` to understand the column structure, identify feature names, and determine the target variable ('mpg').\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22fbfcd6"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction for the subtask is to mount Google Drive to access files from `drive/MyDrive`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97ee67f8",
        "outputId": "12a5e265-1e75-4a7c-f335-2468dcb2219e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b60c93a2"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that Google Drive is mounted, I will open and read the `auto-mpg.names` file from `drive/MyDrive` to understand its content, which describes the column structure and identifies the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "323cf5c7",
        "outputId": "bc2e58f5-6be2-4f44-8950-b20b730220c0"
      },
      "source": [
        "import os\n",
        "\n",
        "directory_path = '/content/drive/MyDrive/Physics Informed ML/HW/auto_mpg'\n",
        "\n",
        "try:\n",
        "    # List contents of the directory\n",
        "    contents = os.listdir(directory_path)\n",
        "    print(f\"Contents of '{directory_path}':\")\n",
        "    for item in contents:\n",
        "        print(item)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The directory '{directory_path}' was not found.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of '/content/drive/MyDrive/Physics Informed ML/HW/auto_mpg':\n",
            "auto-mpg.data\n",
            "auto-mpg.data-original\n",
            "auto-mpg.names\n",
            "Index\n",
            ".ipynb_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hOLIJJwgjvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bcf1241",
        "outputId": "af359817-6ae5-488f-8a45-ed5b434e5028"
      },
      "source": [
        "names_file_path = '/content/drive/MyDrive/Physics Informed ML/HW/auto_mpg/auto-mpg.names'\n",
        "\n",
        "try:\n",
        "    with open(names_file_path, 'r') as f:\n",
        "        names_content = f.read()\n",
        "    print(names_content)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: The file '{names_file_path}' was not found. Please ensure the path is correct.\")\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred: {e}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1. Title: Auto-Mpg Data\n",
            "\n",
            "2. Sources:\n",
            "   (a) Origin:  This dataset was taken from the StatLib library which is\n",
            "                maintained at Carnegie Mellon University. The dataset was \n",
            "                used in the 1983 American Statistical Association Exposition.\n",
            "   (c) Date: July 7, 1993\n",
            "\n",
            "3. Past Usage:\n",
            "    -  See 2b (above)\n",
            "    -  Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning.\n",
            "       In Proceedings on the Tenth International Conference of Machine \n",
            "       Learning, 236-243, University of Massachusetts, Amherst. Morgan\n",
            "       Kaufmann.\n",
            "\n",
            "4. Relevant Information:\n",
            "\n",
            "   This dataset is a slightly modified version of the dataset provided in\n",
            "   the StatLib library.  In line with the use by Ross Quinlan (1993) in\n",
            "   predicting the attribute \"mpg\", 8 of the original instances were removed \n",
            "   because they had unknown values for the \"mpg\" attribute.  The original \n",
            "   dataset is available in the file \"auto-mpg.data-original\".\n",
            "\n",
            "   \"The data concerns city-cycle fuel consumption in miles per gallon,\n",
            "    to be predicted in terms of 3 multivalued discrete and 5 continuous\n",
            "    attributes.\" (Quinlan, 1993)\n",
            "\n",
            "5. Number of Instances: 398\n",
            "\n",
            "6. Number of Attributes: 9 including the class attribute\n",
            "\n",
            "7. Attribute Information:\n",
            "\n",
            "    1. mpg:           continuous\n",
            "    2. cylinders:     multi-valued discrete\n",
            "    3. displacement:  continuous\n",
            "    4. horsepower:    continuous\n",
            "    5. weight:        continuous\n",
            "    6. acceleration:  continuous\n",
            "    7. model year:    multi-valued discrete\n",
            "    8. origin:        multi-valued discrete\n",
            "    9. car name:      string (unique for each instance)\n",
            "\n",
            "8. Missing Attribute Values:  horsepower has 6 missing values\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba68b27b"
      },
      "source": [
        "## Load `auto-mpg.data` into DataFrame from Drive\n",
        "\n",
        "### Subtask:\n",
        "Load the `auto-mpg.data` file from the corresponding path in your `drive/MyDrive` into a pandas DataFrame, using the column names extracted from `auto-mpg.names` and excluding the 'car name' column.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3f0379f9"
      },
      "source": [
        "**Reasoning**:\n",
        "The first instruction is to import the pandas library, which is necessary for creating and manipulating DataFrames.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebe4a9f0",
        "outputId": "42ba80da-224f-48c1-db5a-f729fdaa107f"
      },
      "source": [
        "import pandas as pd\n",
        "print(\"Pandas library imported as pd.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pandas library imported as pd.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fdbd271"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the pandas library is imported, I will proceed to define the column names, construct the file path, load the `auto-mpg.data` into a pandas DataFrame, handling missing values, and then display the head and information of the DataFrame to verify the loading process and data types.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dfb345a",
        "outputId": "dbb52df2-1d1c-4728-f44b-0bfe94bf6c5c"
      },
      "source": [
        "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
        "data_file_path = os.path.join(directory_path, 'auto-mpg.data')\n",
        "\n",
        "# Load the data, handling '?' as missing values and specifying whitespace as separator\n",
        "df_auto_mpg = pd.read_csv(data_file_path, names=column_names, na_values='?', delim_whitespace=True)\n",
        "\n",
        "# Drop the 'car name' column as it's not needed for analysis\n",
        "df_auto_mpg = df_auto_mpg.drop('car name', axis=1)\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df_auto_mpg.head())\n",
        "\n",
        "print(\"\\nDataFrame Information:\")\n",
        "df_auto_mpg.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
            "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
            "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
            "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
            "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
            "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
            "\n",
            "   model year  origin  \n",
            "0          70       1  \n",
            "1          70       1  \n",
            "2          70       1  \n",
            "3          70       1  \n",
            "4          70       1  \n",
            "\n",
            "DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    392 non-null    float64\n",
            " 4   weight        398 non-null    float64\n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            "dtypes: float64(5), int64(3)\n",
            "memory usage: 25.0 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-118887064.py:5: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df_auto_mpg = pd.read_csv(data_file_path, names=column_names, na_values='?', delim_whitespace=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bb0a6ff"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code produced a `FutureWarning` because `delim_whitespace=True` is deprecated. I will update the `pd.read_csv` function call to use `sep='\\s+'` as suggested by the warning for better practice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a0e9168",
        "outputId": "1f973b0d-0a1a-4b23-c910-31f2438e3eaf"
      },
      "source": [
        "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
        "data_file_path = os.path.join(directory_path, 'auto-mpg.data')\n",
        "\n",
        "# Load the data, handling '?' as missing values and specifying whitespace as separator\n",
        "df_auto_mpg = pd.read_csv(data_file_path, names=column_names, na_values='?', sep='\\s+')\n",
        "\n",
        "# Drop the 'car name' column as it's not needed for analysis\n",
        "df_auto_mpg = df_auto_mpg.drop('car name', axis=1)\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df_auto_mpg.head())\n",
        "\n",
        "print(\"\\nDataFrame Information:\")\n",
        "df_auto_mpg.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
            "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
            "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
            "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
            "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
            "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
            "\n",
            "   model year  origin  \n",
            "0          70       1  \n",
            "1          70       1  \n",
            "2          70       1  \n",
            "3          70       1  \n",
            "4          70       1  \n",
            "\n",
            "DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    392 non-null    float64\n",
            " 4   weight        398 non-null    float64\n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            "dtypes: float64(5), int64(3)\n",
            "memory usage: 25.0 KB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
            "<>:5: SyntaxWarning: invalid escape sequence '\\s'\n",
            "/tmp/ipython-input-2403202165.py:5: SyntaxWarning: invalid escape sequence '\\s'\n",
            "  df_auto_mpg = pd.read_csv(data_file_path, names=column_names, na_values='?', sep='\\s+')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8c151e4"
      },
      "source": [
        "**Reasoning**:\n",
        "The previous code generated a `SyntaxWarning` because `\\s` was interpreted as an escape sequence rather than a raw string for the regular expression separator. I will fix this by using a raw string literal `r'\\s+'` for the `sep` argument in `pd.read_csv`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7774c083",
        "outputId": "a79c54cb-d267-4528-e0b1-e0f8d9af42ae"
      },
      "source": [
        "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model year', 'origin', 'car name']\n",
        "data_file_path = os.path.join(directory_path, 'auto-mpg.data')\n",
        "\n",
        "# Load the data, handling '?' as missing values and specifying whitespace as separator\n",
        "df_auto_mpg = pd.read_csv(data_file_path, names=column_names, na_values='?', sep=r'\\s+')\n",
        "\n",
        "# Drop the 'car name' column as it's not needed for analysis\n",
        "df_auto_mpg = df_auto_mpg.drop('car name', axis=1)\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df_auto_mpg.head())\n",
        "\n",
        "print(\"\\nDataFrame Information:\")\n",
        "df_auto_mpg.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the DataFrame:\n",
            "    mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
            "0  18.0          8         307.0       130.0  3504.0          12.0   \n",
            "1  15.0          8         350.0       165.0  3693.0          11.5   \n",
            "2  18.0          8         318.0       150.0  3436.0          11.0   \n",
            "3  16.0          8         304.0       150.0  3433.0          12.0   \n",
            "4  17.0          8         302.0       140.0  3449.0          10.5   \n",
            "\n",
            "   model year  origin  \n",
            "0          70       1  \n",
            "1          70       1  \n",
            "2          70       1  \n",
            "3          70       1  \n",
            "4          70       1  \n",
            "\n",
            "DataFrame Information:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 398 entries, 0 to 397\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   mpg           398 non-null    float64\n",
            " 1   cylinders     398 non-null    int64  \n",
            " 2   displacement  398 non-null    float64\n",
            " 3   horsepower    392 non-null    float64\n",
            " 4   weight        398 non-null    float64\n",
            " 5   acceleration  398 non-null    float64\n",
            " 6   model year    398 non-null    int64  \n",
            " 7   origin        398 non-null    int64  \n",
            "dtypes: float64(5), int64(3)\n",
            "memory usage: 25.0 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edfde339"
      },
      "source": [
        "## Handle Missing Values\n",
        "\n",
        "### Subtask:\n",
        "Inspect the loaded DataFrame for missing values and remove any rows that contain them.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c14f1e7a"
      },
      "source": [
        "**Reasoning**:\n",
        "To address the subtask of handling missing values, I will first inspect the `df_auto_mpg` DataFrame to identify columns with missing values and their counts, then remove rows containing any missing values, and finally verify that all missing values have been successfully removed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2724c01c",
        "outputId": "ab61f12d-9a78-4023-ed1c-f853a3bddaba"
      },
      "source": [
        "print(\"Missing values before dropping rows:\")\n",
        "print(df_auto_mpg.isnull().sum())\n",
        "\n",
        "# Remove rows with any missing values\n",
        "df_auto_mpg = df_auto_mpg.dropna()\n",
        "\n",
        "print(\"\\nMissing values after dropping rows:\")\n",
        "print(df_auto_mpg.isnull().sum())\n",
        "\n",
        "print(\"\\nShape of the DataFrame after dropping rows:\", df_auto_mpg.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values before dropping rows:\n",
            "mpg             0\n",
            "cylinders       0\n",
            "displacement    0\n",
            "horsepower      6\n",
            "weight          0\n",
            "acceleration    0\n",
            "model year      0\n",
            "origin          0\n",
            "dtype: int64\n",
            "\n",
            "Missing values after dropping rows:\n",
            "mpg             0\n",
            "cylinders       0\n",
            "displacement    0\n",
            "horsepower      0\n",
            "weight          0\n",
            "acceleration    0\n",
            "model year      0\n",
            "origin          0\n",
            "dtype: int64\n",
            "\n",
            "Shape of the DataFrame after dropping rows: (392, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c92e3f0c"
      },
      "source": [
        "## Separate Features and Target\n",
        "\n",
        "### Subtask:\n",
        "Split the cleaned DataFrame into features (X) and the target variable (y, which is 'mpg').\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bf77612"
      },
      "source": [
        "**Reasoning**:\n",
        "To separate the features and the target variable, I will create a new DataFrame `X` by dropping the 'mpg' column from `df_auto_mpg` and a Series `y` containing the 'mpg' column. Finally, I will print the first 5 rows of both `X` and `y` to confirm the separation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be5a7bee",
        "outputId": "8c1e68d9-78ce-4806-ddaf-3d1a13638a6b"
      },
      "source": [
        "X = df_auto_mpg.drop('mpg', axis=1)\n",
        "y = df_auto_mpg['mpg']\n",
        "\n",
        "print(\"First 5 rows of features (X):\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\nFirst 5 rows of target (y):\")\n",
        "print(y.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of features (X):\n",
            "   cylinders  displacement  horsepower  weight  acceleration  model year  \\\n",
            "0          8         307.0       130.0  3504.0          12.0          70   \n",
            "1          8         350.0       165.0  3693.0          11.5          70   \n",
            "2          8         318.0       150.0  3436.0          11.0          70   \n",
            "3          8         304.0       150.0  3433.0          12.0          70   \n",
            "4          8         302.0       140.0  3449.0          10.5          70   \n",
            "\n",
            "   origin  \n",
            "0       1  \n",
            "1       1  \n",
            "2       1  \n",
            "3       1  \n",
            "4       1  \n",
            "\n",
            "First 5 rows of target (y):\n",
            "0    18.0\n",
            "1    15.0\n",
            "2    18.0\n",
            "3    16.0\n",
            "4    17.0\n",
            "Name: mpg, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d92384e1"
      },
      "source": [
        "## Encode Categorical Features\n",
        "\n",
        "### Subtask:\n",
        "Identify and one-hot encode any categorical features, specifically the 'origin', 'cylinders', and 'model year' columns, to prepare the data for model training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ad31ec2e"
      },
      "source": [
        "### Identify Categorical Columns\n",
        "\n",
        "**Reasoning**:\n",
        "The categorical columns to be one-hot encoded are explicitly identified as 'cylinders', 'model year', and 'origin' based on the problem description and the subtask instructions. These will be processed using `pd.get_dummies()` in the next step to convert them into a numerical format suitable for machine learning models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b31aa05b"
      },
      "source": [
        "**Reasoning**:\n",
        "Now that the categorical columns have been identified, I will use `pd.get_dummies()` to perform one-hot encoding on 'cylinders', 'model year', and 'origin', setting `drop_first=True` to prevent multicollinearity. Then, I will update the `X` DataFrame with the encoded features and display its head and shape to verify the transformation.\n",
        "\n"
      ]
    }
  ]
}