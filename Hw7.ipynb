{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM/quixUAs27Ng3iYgWks2+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredlan1/getting_started_with_ML/blob/main/Hw7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "Xt7rcV2s5B_P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec8a65fa-d147-4edb-e10b-7cfb97c5da24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "!pip -q install torch matplotlib numpy\n",
        "\n",
        "import os, math, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "606c6ad1",
        "outputId": "34a4a98d-f5a1-4421-d663-6a77d0cad478"
      },
      "source": [
        "\n",
        "file_path = '/content/drive/MyDrive/Physics Informed ML/HW/kdata.txt'\n",
        "\n",
        "\n",
        "ntraj_total = 2148  # number of trajectories\n",
        "nt = 50  # number of time steps\n",
        "ny = 7  # number of states\n",
        "\n",
        "n_train =2048 #20148\n",
        "n_test  = 100\n",
        "seed = 0\n",
        "\n",
        "rng = np.random.default_rng(seed)\n",
        "\n",
        "tvec = np.linspace(0, 350, nt)\n",
        "\n",
        "Y = np.loadtxt(file_path).reshape(ntraj_total, nt, ny).astype(np.float32)\n",
        "\n",
        "# Split like the prompt: first 2048 train-candidate, last 100 test\n",
        "Ytrain_full = Y[:2048]\n",
        "Ytest = Y[2048:2048+n_test]\n",
        "\n",
        "# Subsample training trajectories for fast iteration\n",
        "assert n_train <= len(Ytrain_full)\n",
        "train_idx = rng.choice(len(Ytrain_full), size=n_train, replace=False)\n",
        "Ytrain = Ytrain_full[train_idx]\n",
        "\n",
        "print(\"Ytrain:\", Ytrain.shape, \"Ytest:\", Ytest.shape)\n"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ytrain: (2048, 50, 7) Ytest: (100, 50, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = 1e-8\n",
        "\n",
        "mu=Ytrain.reshape(-1, ny).mean(axis=0)\n",
        "std = Ytrain.reshape(-1,ny).std(axis=0) + eps\n",
        "\n",
        "def normalize(A):\n",
        "    return (A-mu)/ std\n",
        "\n",
        "def denormalize(A):\n",
        "    return A*std+mu\n",
        "\n",
        "Ytrain_n = normalize(Ytrain)\n",
        "Ytest_n = normalize(Ytest)\n",
        "\n",
        "print(\"Train normalized mean (approx):\", Ytrain_n.reshape(-1, ny).mean(axis=0))\n",
        "print(\"Train normalized std  (approx):\", Ytrain_n.reshape(-1, ny).std(axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtAwRcm2HPLk",
        "outputId": "cdfd3cc4-c5c3-4714-842e-25651bc622e5"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train normalized mean (approx): [-1.9077714e-05 -3.8507033e-06 -3.3960318e-05  3.8473681e-05\n",
            "  1.8069846e-05  2.4760458e-05  9.3171993e-06]\n",
            "Train normalized std  (approx): [1.0000019 1.0000073 1.0000019 1.0000086 1.0000073 0.9999975 1.0000008]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Xtrain = torch.tensor(Ytrain_n, dtype=torch.float32) #batch_size,nt,ny\n",
        "Xtest = torch.tensor(Ytest_n, dtype=torch.float32)\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(Xtrain), batch_size=32, shuffle=True, drop_last=True)\n",
        "test_loader = DataLoader(TensorDataset(Xtest), batch_size=64, shuffle= False)\n",
        "\n",
        "next(iter(train_loader))[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ywj4eyyKyD5",
        "outputId": "215bff3a-19bf-425e-893f-1c10871add7f"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 50, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self,in_dim, out_dim, hidden=(128, 128), act=nn.ReLU):\n",
        "      super().__init__()\n",
        "      layers = []\n",
        "      d = in_dim\n",
        "      for h in hidden:\n",
        "          layers += [nn.Linear(d,h), act()]\n",
        "          d = h\n",
        "      layers += [nn.Linear(d, out_dim)]\n",
        "      self.net = nn.Sequential(*layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "      return self.net(x)\n",
        "\n",
        "class KoopmanAE(nn.Module):\n",
        "      def __init__(self, x_dim=7, latent_dim=12, enc_hidden=(128, 128), dec_hidden=(128,128), dropout=0.0):\n",
        "          super().__init__()\n",
        "          self.encoder = MLP(x_dim, latent_dim, enc_hidden)\n",
        "          self.decoder = MLP(latent_dim, x_dim, dec_hidden)\n",
        "          self.dropout = nn.Dropout(dropout) if dropout > 0 else nn.Identity()\n",
        "          self.K = nn.Linear(latent_dim, latent_dim, bias=False)\n",
        "\n",
        "          with torch.no_grad():\n",
        "              self.K.weight.zero_()\n",
        "              self.K.weight += torch.eye(latent_dim)*0.98\n",
        "              self.K.weight +=0.01* torch.randn_like(self.K.weight)\n",
        "\n",
        "\n",
        "      def encode(self, x):\n",
        "          return self.dropout(self.encoder(x))\n",
        "\n",
        "      def decode(self,y):\n",
        "          return self.decoder(y)\n",
        "\n",
        "      def step_latent(self, y):\n",
        "          return self.K(y)\n",
        "\n",
        "      def rollout_latent(self, y0, steps):\n",
        "          ys = [y0]\n",
        "          y = y0\n",
        "          for _ in range(steps-1):\n",
        "              y = self.step_latent(y)\n",
        "              ys.append(y)\n",
        "          return torch.stack(ys, dim=1)\n",
        "\n",
        "      def rollout_x(self, x0, steps):\n",
        "          y0 = self.encode(x0)\n",
        "          Yhat = self.rollout_latent(y0, steps)\n",
        "          Xhat = self.decode(Yhat)\n",
        "          return Xhat, Yhat\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "latent_dim = 8\n",
        "enc_hidden = (128, 128)\n",
        "dec_hidden = (128, 128)\n",
        "dropout = 0\n",
        "\n",
        "\n",
        "model = KoopmanAE(x_dim=ny, latent_dim=latent_dim, enc_hidden = enc_hidden, dec_hidden=dec_hidden, dropout=dropout).to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abVjERQQMpre",
        "outputId": "5bd1fd33-65d9-4d1e-97d5-7d11361eb464"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KoopmanAE(\n",
            "  (encoder): MLP(\n",
            "    (net): Sequential(\n",
            "      (0): Linear(in_features=7, out_features=128, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (3): ReLU()\n",
            "      (4): Linear(in_features=128, out_features=8, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (decoder): MLP(\n",
            "    (net): Sequential(\n",
            "      (0): Linear(in_features=8, out_features=128, bias=True)\n",
            "      (1): ReLU()\n",
            "      (2): Linear(in_features=128, out_features=128, bias=True)\n",
            "      (3): ReLU()\n",
            "      (4): Linear(in_features=128, out_features=7, bias=True)\n",
            "    )\n",
            "  )\n",
            "  (dropout): Identity()\n",
            "  (K): Linear(in_features=8, out_features=8, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mse = nn.MSELoss()\n",
        "\n",
        "def compute_losses(model, Xtraj):\n",
        "    B, T, _ = Xtraj.shape\n",
        "    x0 = Xtraj[:, 0, :]\n",
        "    y0 = model.encode(x0)\n",
        "\n",
        "    Ypred = model. rollout_latent(y0, T)\n",
        "    Xpred = model.decode(Ypred)\n",
        "\n",
        "    Ytrue = model.encode(Xtraj.reshape(B*T, ny)).reshape(B, T, -1)\n",
        "\n",
        "    L_recon = mse(Xpred, Xtraj)\n",
        "    L_lin = mse(Ypred, Ytrue)\n",
        "    L_pred = mse(Xpred, Xtraj)\n",
        "\n",
        "    return L_recon, L_lin, L_pred"
      ],
      "metadata": {
        "id": "NDLTqtUoSaAX"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 1e-3\n",
        "weight_decay =1e-6\n",
        "pretrain_epochs = 50\n",
        "train_epochs = 200\n",
        "alpha_recon = 1.0\n",
        "alpha_pred  = 1.0\n",
        "alpha_lin   = 1.0\n",
        "grad_clip = 1.0\n",
        "\n",
        "opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "def run_epoch(model, loader, train=True, phase='full'):\n",
        "    model.train(train)\n",
        "    tot = {'loss':0.0, 'recon':0.0, 'lin':0.0, 'pred':0.0}\n",
        "    n= 0\n",
        "    for(Xtraj,) in loader:\n",
        "        Xtraj = Xtraj.to(device)\n",
        "        with torch.set_grad_enabled(train):\n",
        "            L_recon, L_lin, L_pred = compute_losses(model, Xtraj)\n",
        "            if phase == 'pretrain':\n",
        "                loss = L_recon\n",
        "\n",
        "            else:\n",
        "                loss = alpha_recon*L_recon + alpha_lin*L_lin +alpha_pred*L_pred\n",
        "\n",
        "            if train:\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                loss.backward()\n",
        "                if grad_clip is not None:\n",
        "                    nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
        "\n",
        "                opt.step()\n",
        "\n",
        "\n",
        "        bs = Xtraj.shape[0]\n",
        "        tot['loss'] +=loss.item()*bs\n",
        "        tot['recon'] += L_recon.item()*bs\n",
        "        tot['lin'] +=L_lin.item()*bs\n",
        "        tot['pred'] += L_pred.item()*bs\n",
        "\n",
        "    for k in tot:\n",
        "        tot[k] /= max(n,1)\n",
        "\n",
        "    return tot\n",
        "\n",
        "history = {'phase':[], 'epoch':[], 'train_loss':[], 'test_loss':[]}\n",
        "\n",
        "\n",
        "# ---- Pretrain ----\n",
        "for ep in range(pretrain_epochs):\n",
        "    tr = run_epoch(model, train_loader, train=True,  phase=\"pretrain\")\n",
        "    te = run_epoch(model, test_loader,  train=False, phase=\"pretrain\")\n",
        "    history[\"phase\"].append(\"pretrain\")\n",
        "    history[\"epoch\"].append(ep)\n",
        "    history[\"train_loss\"].append(tr[\"loss\"])\n",
        "    history[\"test_loss\"].append(te[\"loss\"])\n",
        "    if (ep+1) % 10 == 0:\n",
        "        print(f\"[pretrain {ep+1:4d}] train {tr['loss']:.4e} | test {te['loss']:.4e}\")\n",
        "\n",
        "# ---- Full loss ----\n",
        "for ep in range(train_epochs):\n",
        "    tr = run_epoch(model, train_loader, train=True,  phase=\"full\")\n",
        "    te = run_epoch(model, test_loader,  train=False, phase=\"full\")\n",
        "    history[\"phase\"].append(\"full\")\n",
        "    history[\"epoch\"].append(pretrain_epochs + ep)\n",
        "    history[\"train_loss\"].append(tr[\"loss\"])\n",
        "    history[\"test_loss\"].append(te[\"loss\"])\n",
        "    if (ep+1) % 20 == 0:\n",
        "        print(f\"[full     {ep+1:4d}] train {tr['loss']:.4e} | test {te['loss']:.4e}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xoEkSpdaTLT5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81678c20-7162-42e0-9ccd-be42b567f57d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[pretrain   10] train 1.2022e+03 | test 5.8640e+01\n",
            "[pretrain   20] train 1.0978e+03 | test 5.1655e+01\n",
            "[pretrain   30] train 1.0547e+03 | test 4.7376e+01\n",
            "[pretrain   40] train 9.7117e+02 | test 4.4966e+01\n",
            "[pretrain   50] train 7.8004e+02 | test 3.6424e+01\n",
            "[full       20] train 1.4812e+03 | test 6.6113e+01\n",
            "[full       40] train 1.1704e+03 | test 5.2991e+01\n",
            "[full       60] train 9.8385e+02 | test 5.9806e+01\n",
            "[full       80] train 8.7386e+02 | test 5.4869e+01\n",
            "[full      100] train 7.8433e+02 | test 6.0329e+01\n",
            "[full      120] train 7.4001e+02 | test 6.2811e+01\n",
            "[full      140] train 7.1443e+02 | test 6.3621e+01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = np.array(history[\"epoch\"])\n",
        "train_loss = np.array(history[\"train_loss\"])\n",
        "test_loss  = np.array(history[\"test_loss\"])\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, train_loss, label=\"train\")\n",
        "plt.plot(epochs, test_loss, label=\"test\")\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.ylabel(\"loss (log scale)\")\n",
        "plt.title(\"Training / Testing Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n18ZIGZzTyVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.no_grad()\n",
        "def predict_trajectory(model, Xtraj):\n",
        "  x0 = Xtraj[0].to(device)\n",
        "  Xhat, _ = model.rollout_x(x0[None,:], steps=Xtraj.shape[0])\n",
        "  return Xhat[0].cpu()\n",
        "\n",
        "x_true_n = Xtest[0]\n",
        "x_hat_n = predict_trajectory(model, x_true_n)\n",
        "\n",
        "x_true = denormalize(x_true_n.cpu().detach().numpy())\n",
        "x_hat = denormalize(x_hat_n.cpu().detach().numpy())\n",
        "\n",
        "plt.figure()\n",
        "for i in range(3):\n",
        "    plt.plot(tvec, x_hat[:, i], label=f'model state{i+1}')\n",
        "    plt.plot(tvec, x_true[:, i], linestyle='--', label=f'data state{i+1}')\n",
        "plt.xlabel('t')\n",
        "plt.ylabel('state values')\n",
        "plt.title('Test trajectrory1: data(dashed line) vs model (solidi line)')\n",
        "plt.legend(ncol=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4aOeyGZOWAOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_linear_A(Ytrain_n):\n",
        "    Xk  = Ytrain_n[:, :-1, :].reshape(-1, ny)\n",
        "    Xkp = Ytrain_n[:, 1:,  :].reshape(-1, ny)\n",
        "    A_T, *_ = np.linalg.lstsq(Xk, Xkp, rcond=None)  # Xk @ A_T â‰ˆ Xkp\n",
        "    return A_T.T\n",
        "\n",
        "A = fit_linear_A(Ytrain_n)\n",
        "\n",
        "def rollout_linear_A(A, x0, T):\n",
        "    xs = [x0]\n",
        "    x = x0\n",
        "    for _ in range(T-1):\n",
        "        x = A @ x\n",
        "        xs.append(x)\n",
        "    return np.stack(xs, axis=0)\n",
        "\n",
        "x0 = x_true_n[0].cpu().numpy()\n",
        "xA = rollout_linear_A(A, x0, nt)\n",
        "xA_den = denormalize(xA)\n",
        "\n",
        "plt.figure()\n",
        "for i in range(3):\n",
        "    plt.plot(tvec, xA_den[:, i], label=f\"linear A state {i+1}\")\n",
        "    plt.plot(tvec, x_true[:, i], linestyle=\"--\", label=f\"data state {i+1}\")\n",
        "plt.xlabel(\"t\")\n",
        "plt.ylabel(\"state value\")\n",
        "plt.title(\"Baseline: linear A in original state space\")\n",
        "plt.legend(ncol=2)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U723UQHXX5a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XKCp3b7_Yd3l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}