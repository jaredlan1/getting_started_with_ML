{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0R52m8FNSbw5tiQLPU5Gc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jaredlan1/getting_started_with_ML/blob/main/HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fVj48edkdDH1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------- activation functions -------\n",
        "def relu(z):\n",
        "    if z > 0:\n",
        "        return z\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "def relu_back(xbar, z):\n",
        "    if z > 0:\n",
        "        return xbar\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "identity = lambda z: z\n",
        "\n",
        "identity_back = lambda xbar, z: xbar\n",
        "# -------------------------------------------"
      ],
      "metadata": {
        "id": "O7NycrOVdb0Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- initialization -----------\n",
        "def initialization(nin, nout):\n",
        "    W = np.random.randn(nout, nin)# /np.sqrt(nin)\n",
        "    b = np.zeros((nout, 1))\n",
        "    return W, b\n",
        "# -------------------------------------\n",
        "\n",
        "\n",
        "# -------- loss functions -----------\n",
        "def mse(yhat, y):\n",
        "    diff = yhat-y\n",
        "    sq = diff**2\n",
        "    mse = np.mean(sq)\n",
        "    return mse\n",
        "\n",
        "def mse_back(yhat, y):\n",
        "\n",
        "    # derivative of y of mse\n",
        "    diff = yhat-y\n",
        "    n = y.shape[0]\n",
        "    return  2*(diff) / n\n",
        "# -----------------------------------"
      ],
      "metadata": {
        "id": "iSlikUUkdg6K"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ------------- Layer ------------\n",
        "class Layer:\n",
        "    def __init__(self, nin, nout, activation=identity):\n",
        "        self.W = np.random.rand(nin, nout)\n",
        "        self.b = np.zeros((1, nout))\n",
        "\n",
        "        self.activation = activation\n",
        "        if activation == relu:\n",
        "            self.activation_back = relu_back\n",
        "        if activation == identity:\n",
        "            self.activation_back = identity_back\n",
        "\n",
        "        self.Wbar = None\n",
        "        self.bbar = None\n",
        "\n",
        "        self.X_cache = None\n",
        "        self.Z_cache = None\n",
        "\n",
        "    def forward(self, X, train=True):\n",
        "        Z = X @ self.W + self.b\n",
        "        Xnew = self.activation(Z)\n",
        "\n",
        "        if train:\n",
        "            self.X_cache = X\n",
        "            self.Z_cache = Z\n",
        "\n",
        "        return Xnew\n",
        "\n",
        "    def backward(self, Xnewbar):\n",
        "        Zbar = self.activation_back(Xnewbar, self.Z_cache)\n",
        "\n",
        "        self.Wbar = self.X_cache.T @ Zbar\n",
        "        self.bbar = np.sum(Zbar, axis=0, keepdims=True)\n",
        "\n",
        "        Xbar = Zbar @ self.W.T\n",
        "        return Xbar"
      ],
      "metadata": {
        "id": "29mt4bvKdiEs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network:\n",
        "    def __init__(self, layers, loss):\n",
        "        self.layers = layers\n",
        "\n",
        "        if loss == mse:\n",
        "            self.loss_back = mse_back\n",
        "\n",
        "        # caches\n",
        "        self.yhat_cache = None\n",
        "        self.y_cache = None\n",
        "\n",
        "    def forward(self, X, y, train=True):\n",
        "        # propagate input through layers\n",
        "        for layer in self.layers:\n",
        "            X = layer.forward(X, train=train)\n",
        "\n",
        "        yhat = X\n",
        "        L = mse(yhat, y)\n",
        "\n",
        "        if train:\n",
        "            self.yhat_cache = yhat\n",
        "            self.y_cache = y\n",
        "\n",
        "        return L, yhat\n",
        "\n",
        "    def backward(self):\n",
        "        # start from loss gradient\n",
        "        Lbar = self.loss_back(self.yhat_cache, self.y_cache)\n",
        "\n",
        "        # backprop through layers\n",
        "        for layer in reversed(self.layers):\n",
        "            Lbar = layer.backward(Lbar)\n",
        "\n"
      ],
      "metadata": {
        "id": "6E1BOBFpdkg7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientDescent:\n",
        "\n",
        "    def __init__(self, alpha):\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def step(self, network):\n",
        "        for layer in network.layer\n",
        "\n",
        "          layer.W -= self.alpha * layer.Wbar\n",
        "          layer.b -= self..alpha * layerbbar\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    # ---------- data preparation ----------------\n",
        "    # Initialize lists for the numeric data and the string data\n",
        "    numeric_data = []\n",
        "\n",
        "    # Read the text file\n",
        "    with open('auto-mpg.data', 'r') as file:\n",
        "        for line in file:\n",
        "            # Split the line into columns\n",
        "            columns = line.strip().split()\n",
        "\n",
        "            # Check if any of the first 8 columns contain '?'\n",
        "            if '?' in columns[:8]:\n",
        "                continue  # Skip this line if there's a missing value\n",
        "\n",
        "            # Convert the first 8 columns to floats and append to numeric_data\n",
        "            numeric_data.append([float(value) for value in columns[:8]])\n",
        "\n",
        "    # Convert numeric_data to a numpy array for easier manipulation\n",
        "    numeric_array = np.array(numeric_data)\n"
      ],
      "metadata": {
        "id": "8FJ4Sl3ddvWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the numeric array and the corresponding string array\n",
        "    nrows = numeric_array.shape[0]\n",
        "    indices = np.arange(nrows)\n",
        "    np.random.shuffle(indices)\n",
        "    shuffled_numeric_array = numeric_array[indices]\n",
        "\n",
        "    # Split into training (80%) and test (20%) sets\n",
        "    split_index = int(0.8 * nrows)\n",
        "\n",
        "    train_numeric = shuffled_numeric_array[:split_index]\n",
        "    test_numeric = shuffled_numeric_array[split_index:]\n",
        "\n",
        "    # separate inputs/outputs\n",
        "    Xtrain = train_numeric[:, 1:]\n",
        "    ytrain = train_numeric[:, 0]\n",
        "\n",
        "    Xtest = test_numeric[:, 1:]\n",
        "    ytest = test_numeric[:, 0]\n",
        "\n",
        "    # normalize\n",
        "    Xmean = np.mean(Xtrain, axis=0)\n",
        "    Xstd = np.std(Xtrain, axis=0)\n",
        "    ymean = np.mean(ytrain)\n",
        "    ystd = np.std(ytrain)\n",
        "\n",
        "    Xtrain = (Xtrain - Xmean) / Xstd\n",
        "    Xtest = (Xtest - Xmean) / Xstd\n",
        "    ytrain = (ytrain - ymean) / ystd\n",
        "    ytest = (ytest - ymean) / ystd\n",
        "\n",
        "    # reshape arrays (opposite order of pytorch, here we have nx x ns).\n",
        "    # I found that to be more conveient with the way I did the math operations, but feel free to setup\n",
        "    # however you like.\n",
        "    Xtrain = Xtrain.T\n",
        "    Xtest = Xtest.T\n",
        "    ytrain = np.reshape(ytrain, (1, len(ytrain)))\n",
        "    ytest = np.reshape(ytest, (1, len(ytest)))\n",
        "\n",
        "    # ------------------------------------------------------------\n",
        "\n",
        "    l1 = Layer(7, ?, relu)\n",
        "    # TODO\n",
        "    layers = [l1, l2, l3]\n",
        "    network = Network(layers, mse)\n",
        "    alpha = ?\n",
        "    optimizer = GradientDescent(alpha)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    epochs = ?\n",
        "    for i in range(epochs):\n",
        "        # TODO: run train set, backprop, step\n",
        "\n",
        "        # TODO: run test set\n",
        "\n",
        "\n",
        "    # --- inference ----\n",
        "    _, yhat = network.forward(Xtest, ytest, train=False)\n",
        "\n",
        "    # unnormalize\n",
        "    yhat = (yhat * ystd) + ymean\n",
        "    ytest = (ytest * ystd) + ymean\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n",
        "    plt.plot(range(1, epochs + 1), test_losses, label='Testing Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Testing Losses')\n",
        "    plt.legend()\n",
        "\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(ytest.T, yhat.T, \"o\")\n",
        "    plt.plot([10, 45], [10, 45], \"--\")\n",
        "\n",
        "    print(\"avg error (mpg) =\", np.mean(np.abs(yhat - ytest)))\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "l7UrOMGydzo1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}